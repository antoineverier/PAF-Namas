{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b4900f-deed-437f-b888-c40d5ce4b072",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\Sara Meziane\\Desktop\\telecom\\paf\\git_first'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SARAME~1\\AppData\\Local\\Temp/ipykernel_24784/3900378639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SARAME~1\\AppData\\Local\\Temp/ipykernel_24784/3900378639.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Read RGB image and it's noisy version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'git_first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'git_second.bmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m                                (plugin, kind))\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    258\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\Sara Meziane\\Desktop\\telecom\\paf\\git_first'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import piq\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def main():\n",
    "    # Read RGB image and it's noisy version\n",
    "    x = torch.tensor(imread('git_first.bmp')).permute(2, 0, 1)[None, ...] / 255.\n",
    "    y = torch.tensor(imread('git_second.bmp')).permute(2, 0, 1)[None, ...] / 255.\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # Move to GPU to make computaions faster\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    # To compute BRISQUE score as a measure, use lower case function from the library\n",
    "    brisque_index: torch.Tensor = piq.brisque(x, data_range=1., reduction='none')\n",
    "    # In order to use BRISQUE as a loss function, use corresponding PyTorch module.\n",
    "    # Note: the back propagation is not available using torch==1.5.0.\n",
    "    # Update the environment with latest torch and torchvision.\n",
    "    brisque_loss: torch.Tensor = piq.BRISQUELoss(data_range=1., reduction='none')(x)\n",
    "    print(f\"BRISQUE index: {brisque_index.item():0.4f}, loss: {brisque_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute Content score as a loss function, use corresponding PyTorch module\n",
    "    # By default VGG16 model is used, but any feature extractor model is supported.\n",
    "    # Don't forget to adjust layers names accordingly. Features from different layers can be weighted differently.\n",
    "    # Use weights parameter. See other options in class docstring.\n",
    "    content_loss = piq.ContentLoss(\n",
    "        feature_extractor=\"vgg16\", layers=(\"relu3_3\",), reduction='none')(x, y)\n",
    "    print(f\"ContentLoss: {content_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute DISTS as a loss function, use corresponding PyTorch module\n",
    "    # By default input images are normalized with ImageNet statistics before forwarding through VGG16 model.\n",
    "    # If there is no need to normalize the data, use mean=[0.0, 0.0, 0.0] and std=[1.0, 1.0, 1.0].\n",
    "    dists_loss = piq.DISTS(reduction='none')(x, y)\n",
    "    print(f\"DISTS: {dists_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute DSS as a measure, use lower case function from the library\n",
    "    dss_index: torch.Tensor = piq.dss(x, y, data_range=1., reduction='none')\n",
    "    # In order to use DSS as a loss function, use corresponding PyTorch module\n",
    "    dss_loss = piq.DSSLoss(data_range=1., reduction='none')(x, y)\n",
    "    print(f\"DSS index: {dss_index.item():0.4f}, loss: {dss_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute FSIM as a measure, use lower case function from the library\n",
    "    fsim_index: torch.Tensor = piq.fsim(x, y, data_range=1., reduction='none')\n",
    "    # In order to use FSIM as a loss function, use corresponding PyTorch module\n",
    "    fsim_loss = piq.FSIMLoss(data_range=1., reduction='none')(x, y)\n",
    "    print(f\"FSIM index: {fsim_index.item():0.4f}, loss: {fsim_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute GMSD as a measure, use lower case function from the library\n",
    "    # This is port of MATLAB version from the authors of original paper.\n",
    "    # In any case it should me minimized. Usually values of GMSD lie in [0, 0.35] interval.\n",
    "    gmsd_index: torch.Tensor = piq.gmsd(x, y, data_range=1., reduction='none')\n",
    "    # In order to use GMSD as a loss function, use corresponding PyTorch module:\n",
    "    gmsd_loss: torch.Tensor = piq.GMSDLoss(data_range=1., reduction='none')(x, y)\n",
    "    print(f\"GMSD index: {gmsd_index.item():0.4f}, loss: {gmsd_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute HaarPSI as a measure, use lower case function from the library\n",
    "    # This is port of MATLAB version from the authors of original paper.\n",
    "    haarpsi_index: torch.Tensor = piq.haarpsi(x, y, data_range=1., reduction='none')\n",
    "    # In order to use HaarPSI as a loss function, use corresponding PyTorch module\n",
    "    haarpsi_loss: torch.Tensor = piq.HaarPSILoss(data_range=1., reduction='none')(x, y)\n",
    "    print(f\"HaarPSI index: {haarpsi_index.item():0.4f}, loss: {haarpsi_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute LPIPS as a loss function, use corresponding PyTorch module\n",
    "    lpips_loss: torch.Tensor = piq.LPIPS(reduction='none')(x, y)\n",
    "    print(f\"LPIPS: {lpips_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute MDSI as a measure, use lower case function from the library\n",
    "    mdsi_index: torch.Tensor = piq.mdsi(x, y, data_range=1., reduction='none')\n",
    "    # In order to use MDSI as a loss function, use corresponding PyTorch module\n",
    "    mdsi_loss: torch.Tensor = piq.MDSILoss(data_range=1., reduction='none')(x, y)\n",
    "    print(f\"MDSI index: {mdsi_index.item():0.4f}, loss: {mdsi_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute MS-SSIM index as a measure, use lower case function from the library:\n",
    "    ms_ssim_index: torch.Tensor = piq.multi_scale_ssim(x, y, data_range=1.)\n",
    "    # In order to use MS-SSIM as a loss function, use corresponding PyTorch module:\n",
    "    ms_ssim_loss = piq.MultiScaleSSIMLoss(data_range=1., reduction='none').to(x.device)(x, y)\n",
    "    print(f\"MS-SSIM index: {ms_ssim_index.item():0.4f}, loss: {ms_ssim_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute Multi-Scale GMSD as a measure, use lower case function from the library\n",
    "    # It can be used both as a measure and as a loss function. In any case it should me minimized.\n",
    "    # By default scale weights are initialized with values from the paper.\n",
    "    # You can change them by passing a list of 4 variables to scale_weights argument during initialization\n",
    "    # Note that input tensors should contain images with height and width equal 2 ** number_of_scales + 1 at least.\n",
    "    ms_gmsd_index: torch.Tensor = piq.multi_scale_gmsd(\n",
    "        x, y, data_range=1., chromatic=True, reduction='none')\n",
    "    # In order to use Multi-Scale GMSD as a loss function, use corresponding PyTorch module\n",
    "    ms_gmsd_loss: torch.Tensor = piq.MultiScaleGMSDLoss(\n",
    "        chromatic=True, data_range=1., reduction='none').to(x.device)(x, y)\n",
    "    print(f\"MS-GMSDc index: {ms_gmsd_index.item():0.4f}, loss: {ms_gmsd_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute PSNR as a measure, use lower case function from the library.\n",
    "    psnr_index = piq.psnr(x, y, data_range=1., reduction='none')\n",
    "    print(f\"PSNR index: {psnr_index.item():0.4f}\")\n",
    "\n",
    "    # To compute PieAPP as a loss function, use corresponding PyTorch module:\n",
    "    pieapp_loss: torch.Tensor = piq.PieAPP(reduction='none', stride=32)(x, y)\n",
    "    print(f\"PieAPP loss: {pieapp_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute SSIM index as a measure, use lower case function from the library:\n",
    "    ssim_index = piq.ssim(x, y, data_range=1.)\n",
    "    # In order to use SSIM as a loss function, use corresponding PyTorch module:\n",
    "    ssim_loss: torch.Tensor = piq.SSIMLoss(data_range=1.)(x, y)\n",
    "    print(f\"SSIM index: {ssim_index.item():0.4f}, loss: {ssim_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute Style score as a loss function, use corresponding PyTorch module:\n",
    "    # By default VGG16 model is used, but any feature extractor model is supported.\n",
    "    # Don't forget to adjust layers names accordingly. Features from different layers can be weighted differently.\n",
    "    # Use weights parameter. See other options in class docstring.\n",
    "    style_loss = piq.StyleLoss(feature_extractor=\"vgg16\", layers=(\"relu3_3\",))(x, y)\n",
    "    print(f\"Style: {style_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute TV as a measure, use lower case function from the library:\n",
    "    tv_index: torch.Tensor = piq.total_variation(x)\n",
    "    # In order to use TV as a loss function, use corresponding PyTorch module:\n",
    "    tv_loss: torch.Tensor = piq.TVLoss(reduction='none')(x)\n",
    "    print(f\"TV index: {tv_index.item():0.4f}, loss: {tv_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute VIF as a measure, use lower case function from the library:\n",
    "    vif_index: torch.Tensor = piq.vif_p(x, y, data_range=1.)\n",
    "    # In order to use VIF as a loss function, use corresponding PyTorch class:\n",
    "    vif_loss: torch.Tensor = piq.VIFLoss(sigma_n_sq=2.0, data_range=1.)(x, y)\n",
    "    print(f\"VIFp index: {vif_index.item():0.4f}, loss: {vif_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute VSI score as a measure, use lower case function from the library:\n",
    "    vsi_index: torch.Tensor = piq.vsi(x, y, data_range=1.)\n",
    "    # In order to use VSI as a loss function, use corresponding PyTorch module:\n",
    "    vsi_loss: torch.Tensor = piq.VSILoss(data_range=1.)(x, y)\n",
    "    print(f\"VSI index: {vsi_index.item():0.4f}, loss: {vsi_loss.item():0.4f}\")\n",
    "\n",
    "    # To compute SR-SIM score as a measure, use lower case function from the library:\n",
    "    srsim_index: torch.Tensor = piq.srsim(x, y, data_range=1.)\n",
    "    # In order to use SR-SIM as a loss function, use corresponding PyTorch module:\n",
    "    srsim_loss: torch.Tensor = piq.SRSIMLoss(data_range=1.)(x, y)\n",
    "    print(f\"SR-SIM index: {srsim_index.item():0.4f}, loss: {srsim_loss.item():0.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5dfc0-5e27-4d74-8783-71b07d976cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
